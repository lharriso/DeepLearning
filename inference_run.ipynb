{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateMemeClassifier(torch.nn.Module):\n",
    "    def __init__(self,fusion_method, visual_embedder='vit',wandb_run=None):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        fusion_method: 'concatenate' or 'weight_ensemble' or 'linear_weight_ensemble' or 'visualbert'\n",
    "        visual_embedder: 'vit'\n",
    "        \"\"\"\n",
    "        super(HateMemeClassifier, self).__init__()\n",
    "        self.fusion_method = fusion_method # 'concatenate' or 'weight_ensemble' or 'linear_weight_ensemble' or 'visualbert'\n",
    "        self.wandb_run=wandb_run\n",
    "\n",
    "        configuration = VisualBertConfig.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre',\n",
    "                                                hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\n",
    "        self.visualbert = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre', config=configuration)\n",
    "        if self.fusion_method != 'visualbert':\n",
    "            self.bertmodel = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        if visual_embedder=='vit':\n",
    "            self.embed_cls = nn.Linear(768, 1024)\n",
    "        self.num_labels = 2\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        if self.fusion_method=='weight_ensemble':\n",
    "            self.alpha = nn.Parameter(torch.tensor(0.5))  # Initial value of alpha\n",
    "            \n",
    "        if self.fusion_method=='linear_weight_ensemble':\n",
    "            self.alpha = nn.Parameter(torch.tensor(0.5))  # Initial value of alpha\n",
    "            self.cls_visual = nn.Sequential(\n",
    "                nn.Linear(768, 768),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.BatchNorm1d(768),\n",
    "            )\n",
    "            self.cls_text = nn.Sequential(\n",
    "                nn.Linear(768, 768),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.BatchNorm1d(768),\n",
    "            )\n",
    "\n",
    "        self.cls=nn.Linear(768, self.num_labels)\n",
    "\n",
    "        # Calculate the weights for the loss function and weight balanced loss\n",
    "        nSamples = [5450,3050]\n",
    "        normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "        self.loss_fct = CrossEntropyLoss(weight=torch.FloatTensor(normedWeights))\n",
    "\n",
    "        # self.loss_fct = CrossEntropyLoss()\n",
    "        \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, visual_embeds, visual_attention_mask,\n",
    "                visual_token_type_ids, labels,caption_input_ids, caption_attention_mask, caption_token_type_ids):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        visual_embeds_cls = self.embed_cls(visual_embeds)\n",
    "        \n",
    "        outputs = self.visualbert(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                visual_embeds=visual_embeds_cls,\n",
    "                visual_attention_mask=visual_attention_mask,\n",
    "                visual_token_type_ids=visual_token_type_ids,\n",
    "            )\n",
    "        \n",
    "        visualbert_embedding = outputs[1] # output is a context vector of 768 dimensions\n",
    "\n",
    "        if self.fusion_method != \"visualbert\":\n",
    "        \n",
    "            caption_outputs = self.bertmodel(caption_input_ids, attention_mask=caption_attention_mask, token_type_ids=caption_token_type_ids)\n",
    "                    \n",
    "            # Get the embeddings of the [CLS] token\n",
    "            caption_embeddings = caption_outputs.last_hidden_state[:,0,:] # output is a context vector of 768 dimensions\n",
    "        \n",
    "        if self.fusion_method=='weight_ensemble':\n",
    "            # funsion model: weight ensenble of the two embeddings: alpha*visualbert_embedding + (1-alpha)*caption_embeddings \n",
    "            fused_embedding = self.alpha * self.dropout(visualbert_embedding) + (1-self.alpha) * self.dropout(caption_embeddings)\n",
    "            self.wandb_run.log({\"alpha\": self.alpha.data.cpu().numpy()},commit=False)\n",
    "        \n",
    "            logits = self.cls(fused_embedding)\n",
    "        if self.fusion_method=='linear_weight_ensemble':\n",
    "            # funsion model: weight ensenble of the two embeddings: alpha*visualbert_embedding + (1-alpha)*caption_embeddings \n",
    "            fused_embedding = self.alpha * self.cls_visual(visualbert_embedding) + (1-self.alpha) * self.cls_text(caption_embeddings)\n",
    "            self.wandb_run.log({\"alpha\": self.alpha.data.cpu().numpy()},commit=False)\n",
    "        \n",
    "            logits = self.cls(fused_embedding)\n",
    "        \n",
    "        if self.fusion_method=='visualbert':\n",
    "            logits = self.cls(self.dropout(visualbert_embedding))\n",
    "            \n",
    "        if self.fusion_method=='concatenate':\n",
    "            # funsion model: concatenate the two embeddings\n",
    "            fused_embedding = torch.cat((visualbert_embedding, caption_embeddings), dim=1)\n",
    "            logits = self.cls(fused_embedding)\n",
    "        \n",
    "        \n",
    "        reshaped_logits = logits.view(-1, self.num_labels)\n",
    "        loss = self.loss_fct(reshaped_logits, labels.view(-1))\n",
    "      \n",
    "        return loss, reshaped_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b78064a-3768-4aca-9eb5-8158619b4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-25 22:50:38.547665: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-25 22:50:38.708508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-25 22:50:38.708565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-25 22:50:38.726793: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-25 22:50:38.774998: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-25 22:50:38.775838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-25 22:50:39.997390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jessica/EPFL/Course/EE559-DeepLearning/Project/DeepLearning/model/model.py:21: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  acc_metric = load_metric('accuracy')\n",
      "/home/jessica/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/jessica/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/jessica/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/precision/precision.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/jessica/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/recall/recall.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/jessica/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: \"best_model/hatefulmemcladdifier_weight_ensemble_vit_smooth-totem-17_202405230523/checkpoint-3000/model.safetensors\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Load the model weights from the safetensors file\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Prepare evaluation dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_project_310/lib/python3.10/site-packages/safetensors/torch.py:311\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03mLoads a safetensors file into torch format.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    313\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mget_tensor(k)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"best_model/hatefulmemcladdifier_weight_ensemble_vit_smooth-totem-17_202405230523/checkpoint-3000/model.safetensors\""
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Trainer, AutoTokenizer, TrainingArguments\n",
    "from model.model import HatefulMemesData, HateMemeClassifier, compute_metrics\n",
    "from safetensors.torch import load_file\n",
    "import os\n",
    "\n",
    "# Prepare directories\n",
    "data_folder_path = \"data/hateful_memes\" \n",
    "checkpoint_path = \"/scratch/izar/cchang/EE559/model-checkpoint/hatefulmemcladdifier_weight_ensemble_vit_smooth-totem-17_202405230523/checkpoint-3000\"\n",
    "query = 'query_8' \n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define paths for evaluation data\n",
    "validation_data_path = os.path.join(data_folder_path, 'query236/dev_seen_.jsonl')\n",
    "img_inpainted_dir = os.path.join(data_folder_path, 'img')\n",
    "visual_embed_model = 'vit'  \n",
    "fusion_method = 'weight_ensemble'\n",
    "seq_len = 50\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HateMemeClassifier(fusion_method=fusion_method, visual_embedder=visual_embed_model)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the model weights from the safetensors file\n",
    "state_dict = load_file(os.path.join(checkpoint_path, \"model.safetensors\"))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Prepare evaluation dataset\n",
    "eval_dataset = HatefulMemesData(\n",
    "    validation_data_path, \n",
    "    img_inpainted_dir, \n",
    "    tokenizer, \n",
    "    sequence_length=seq_len, \n",
    "    query=query, \n",
    "    visual_embed_model=visual_embed_model, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Define training arguments (only evaluation relevant parameters)\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",  \n",
    "    per_device_eval_batch_size=24\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbf6f4-68e5-405e-aafa-1e387340460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
